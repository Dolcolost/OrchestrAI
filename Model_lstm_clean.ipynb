{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1368b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pretty_midi\n",
    "import sys\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import LSTM, Dense, Input, Dropout\n",
    "from tensorflow.keras.mixed_precision import LossScaleOptimizer\n",
    "data_dir_X = \"D:/PA/numpy/\"\n",
    "data_dir_Y = \"D:/PA/midi/\" \n",
    "file_list_X = os.listdir(data_dir_X)\n",
    "file_list_Y = os.listdir(data_dir_Y)\n",
    "file_list_numpy = os.listdir(data_dir_X)  # list all files in the directory\n",
    "file_list_midi = os.listdir(data_dir_Y)  # list all files in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abbb475",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc3ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(file_list_numpy, file_list_midi, batch_size):\n",
    "    \n",
    "    #fill batch\n",
    "    curIndex = 0\n",
    "    batch_x = np.zeros((batch_size,160000))\n",
    "    batch_y = np.zeros((batch_size,2502))\n",
    "    while True:\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            \n",
    "            #get X\n",
    "            file_path = os.path.join(data_dir_X, file_list_numpy[curIndex])\n",
    "            x_train = np.load(file_path).flatten()\n",
    "            \n",
    "            \n",
    "            #get Y\n",
    "            midi_data = pretty_midi.PrettyMIDI(data_dir_Y + file_list_midi[curIndex])\n",
    "            instr_notes = []\n",
    "            y = []\n",
    "            y_train = []\n",
    "            \n",
    "            for instr in midi_data.instruments:\n",
    "                for note in instr.notes:\n",
    "                    instr_notes.append((instr.name, pretty_midi.note_number_to_name(note.pitch), note))\n",
    "\n",
    "\n",
    "            instr_notes.sort(key=lambda tup: (tup[2].start, tup[2].end))\n",
    "            for j, note in enumerate(instr_notes):\n",
    "                y.append(round(note[2].start, 3))\n",
    "                y.append(round(note[2].end, 3))\n",
    "                y.append(note[2].pitch)\n",
    "            y_train.append(y)\n",
    "\n",
    "            y_train = np.array(y_train)\n",
    "            \n",
    "            normalized_y_train = []\n",
    "            padded_y_train = pad_sequences(y_train, 2502, padding='post', dtype='float')\n",
    "            normalized_y_train = np.array(padded_y_train)\n",
    "            \n",
    "            batch_x[i] = x_train\n",
    "            batch_y[i] = normalized_y_train[0]\n",
    "            \n",
    "            if i == len(file_list_numpy)-2:\n",
    "                i = 0\n",
    "                \n",
    "            if curIndex == len(file_list_numpy)-2:\n",
    "                curIndex = 0\n",
    "                \n",
    "            curIndex += 1\n",
    "            \n",
    "        \n",
    "        yield batch_x.reshape( batch_size, -1, batch_x.shape[1]), batch_y.reshape( batch_size, -1, batch_y.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d78ee78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#normalized_y_train = normalized_y_train.reshape(normalized_y_train.shape[0], normalized_y_train.shape[2])\n",
    "\n",
    "input_shape = (1, 160000)\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "lstm_out = LSTM(256, return_sequences=True, return_state=True)(inputs) # return_state return 3 outputs\n",
    "lstm_out = LSTM(256, return_sequences=True, return_state=True)(lstm_out)\n",
    "lstm_out = LSTM(256, return_sequences=True, return_state=True)(lstm_out)\n",
    "lstm_out = LSTM(256, return_sequences=True, return_state=True)(lstm_out)\n",
    "lstm_out = LSTM(256, return_sequences=True, return_state=True)(lstm_out)\n",
    "lstm_out = LSTM(256, return_sequences=True, return_state=True)(lstm_out)\n",
    "lstm_out = LSTM(256, return_sequences=True, return_state=True)(lstm_out)\n",
    "lstm_out = LSTM(256, return_sequences=True, return_state=True)(lstm_out)\n",
    "lstm_out = LSTM(256, return_sequences=True, return_state=True)(lstm_out)\n",
    "lstm_out = LSTM(256, return_sequences=True)(lstm_out) # return output gate only\n",
    "output = Dense(2501, activation='relu')(lstm_out)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "def custom_loss(rewards):\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        \n",
    "        cross_entropy_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "        weighted_loss = tf.multiply(rewards, cross_entropy_loss)\n",
    "        return tf.reduce_mean(weighted_loss)\n",
    "    return loss_fn\n",
    "\n",
    "rewards = tf.constant([1.0, 0.5, 0.2])\n",
    "\n",
    "model.compile(optimizer='adam', loss=custom_loss(rewards))\n",
    "\n",
    "model.fit_generator(generator(file_list_numpy, file_list_midi, 5),steps_per_epoch=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8209fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_true, y_pred):\n",
    "        \n",
    "        cross_entropy_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "        weighted_loss = tf.multiply(rewards, cross_entropy_loss)\n",
    "        return tf.reduce_mean(weighted_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d920ab9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_shape = (1, 160000)\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "layer1 = LSTM(256, return_sequences=True)(inputs)\n",
    "layer3 = Dense(4096, activation = 'relu')(layer1)\n",
    "layer4 = Dropout(0.1)(layer3)\n",
    "layer5 = Dense(4096, activation = 'sigmoid')(layer4)\n",
    "layer6 = Dropout(0.1)(layer5)\n",
    "layer7 = Dense(4096, activation = 'sigmoid')(layer6)\n",
    "layer8 = Dropout(0.1)(layer7)\n",
    "layer9 = Dense(4096, activation = 'relu')(layer8)\n",
    "\n",
    "output = Dense(2502, activation='relu')(layer9)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "def custom_loss(rewards):\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        \n",
    "        cross_entropy_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "        weighted_loss = tf.multiply(rewards, cross_entropy_loss)\n",
    "        return tf.reduce_mean(weighted_loss)\n",
    "    return loss_fn\n",
    "\n",
    "rewards = tf.constant([1.0, 0.5, 0.2])\n",
    "\n",
    "model.compile(optimizer='adam', loss=custom_loss(rewards))\n",
    "\n",
    "model.fit_generator(generator(file_list_numpy, file_list_midi, 5),steps_per_epoch=10, epochs=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388733b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 160000)\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "layer1 = LSTM(256, return_sequences=True)(inputs)\n",
    "output = Dense(2502, activation='relu')(layer1)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "model.fit_generator(generator(file_list_numpy, file_list_midi, 5),steps_per_epoch=10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d59ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/model_docker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582c9847",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model/lstm_dense_simgoid2_relu', custom_objects={'loss_fn': loss_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6311e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"test_model\"  # directory where your numpy arrays are located\n",
    "file_list = os.listdir(data_dir)  # list all files in the directory\n",
    "x_test = []\n",
    "\n",
    "# loop over all files in the directory and load the numpy arrays\n",
    "for file_name in file_list:\n",
    "    if file_name.endswith(\".npy\"):  # check if the file is a numpy array\n",
    "        file_path = os.path.join(data_dir, file_name)\n",
    "        x_test.append(np.load(file_path).flatten())\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "# Reshape x_train to have 3 dimensions\n",
    "x_test = x_test.reshape( x_test.shape[0], -1, x_test.shape[1])\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3214c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(x_test)\n",
    "\n",
    "result = np.array(result)\n",
    "result = np.maximum(result.round(3),0)\n",
    "\n",
    "pitch_output = np.array(result[0][2::3], dtype='int')\n",
    "pitch_output = np.minimum(pitch_output,127)\n",
    "start_time_output = result[0][0::3]\n",
    "end_time_output = result[0][1::3]\n",
    "\n",
    "print(start_time_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.array(result)\n",
    "result = np.maximum(result.round(3),0)\n",
    "\n",
    "pitch_output = np.array(result[0][0][2::3], dtype='int')\n",
    "pitch_output = np.minimum(pitch_output,127)\n",
    "start_time_output = result[0][0][0::3]\n",
    "end_time_output = result[0][0][1::3]\n",
    "\n",
    "print(start_time_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5470573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = pretty_midi.PrettyMIDI(initial_tempo=80)\n",
    "velocity = 100\n",
    "inst = pretty_midi.Instrument(program=0, is_drum=False, name='piano')\n",
    "pm.instruments.append(inst)\n",
    "for i in range(len(pitch_output)):\n",
    "    \n",
    "    inst.notes.append(pretty_midi.Note(velocity, pitch_output[i], start_time_output[i], end_time_output[i]))\n",
    "\n",
    "\n",
    "    \n",
    "print('There are {} time signature changes'.format(len(pm.time_signature_changes)))\n",
    "print('There are {} instruments'.format(len(pm.instruments)))\n",
    "print('Instrument 1 has {} notes'.format(len(pm.instruments[0].notes)))\n",
    "print('Instrument 1 has {} pitch bends'.format(len(pm.instruments[0].pitch_bends)))\n",
    "print('Instrument 1 has {} control changes'.format(len(pm.instruments[0].control_changes)))\n",
    "\n",
    "pm.write('outLstm6.mid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f877e665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load x\n",
    "file_list_numpy = os.listdir('path')  # list all files in the directory\n",
    "rewards = [0.1,0.8,0.6,1,0.6]\n",
    "x_train = []\n",
    "\n",
    "for i in range(len(rewards)):\n",
    "\n",
    "    file_path = os.path.join('path', file_list_numpy[i])\n",
    "    x_train.append(np.load(file_path).flatten())\n",
    "\n",
    "\n",
    "def loss_fn(reward, y_pred):\n",
    "    cross_entropy_loss = tf.keras.losses.BinaryCrossentropy(y_pred)\n",
    "    weighted_loss = tf.multiply(reward, cross_entropy_loss)\n",
    "    return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "# load the model with the custom loss\n",
    "model = load_model('model/lstm_dense_simgoid2_relu', custom_objects={'loss_fn': loss_fn})\n",
    "\n",
    "# compile the model with the custom loss function\n",
    "model.compile(optimizer='adam', loss=loss_fn)\n",
    "\n",
    "# now you can train the model\n",
    "model.fit(x_train, rewards, epoch=len(rewards))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e7929d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc71d597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
